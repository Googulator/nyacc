\input texinfo.tex
@setfilename nyacc-ug.info
@settitle Not Yet Another Compiler Compiler!

@copying
Copyright (C) 2015,2016 -- Matthew R. Wette.

Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3 or
any later version published by the Free Software Foundation; with no
Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts.  A
copy of the license is included with the distribution as COPYING.DOC.
@end copying

@clear skip

@titlepage
@title Not Yet Another Compiler-Compiler!
@subtitle A LALR(1) Parser Generator Implemented in Guile
@author Matt Wette
@end titlepage

@ifnottex
@node Top, Introduction, (dir), (dir)
@top NYACC Manual
@end ifnottex

@menu
* Introduction::
* Parsing::
* Translation::
* Administrative::
* Todos::
* References::
@end menu


@node Introduction
@chapter Introduction

WARNING: This manual is currently in a very immature state.

A LALR(1) parser is a pushdown automata for parsing computer languages.
In this tool the automata, along with its auxiliary parameters
(e.g., actions), is called a @emph{machine}.  The grammar is called 
the @emph{specification}.  The program that processes, driven by the 
machine, input token to generate a final output, or error, is 
the @emph{parser}.

@section Example for Simple or Development Parser

A simplest way to introduce working with @code{nyacc} is to work through
an example.  Consider the following contents of the file @file{calc.scm}.
@example
(use-modules (nyacc lalr))
(use-modules (nyacc lex))

(define calc-spec
  (lalr-spec
   (prec< (left "+" "-") (left "*" "/"))
   (start expr)
   (grammar
    (expr
     (expr "+" expr ($$ (+ $1 $3)))
     (expr "-" expr ($$ (- $1 $3)))
     (expr "*" expr ($$ (* $1 $3)))
     (expr "/" expr ($$ (/ $1 $3)))
     ('$fx ($$ (string->number $1)))))))

(define calc-mach (make-lalr-machine calc-spec))

(define parse-expr
  (let ((gen-lexer (make-lexer-generator (assq-ref calc-mach 'mtab)))
	(calc-parser (make-lalr-parser calc-mach)))
    (lambda () (calc-parser (gen-lexer)))))

(define res (with-input-from-string "1 + 4 / 2 * 3 - 5" parse-expr))
(simple-format #t "expect 2; get ~S\n" res) ;; expect: 2
@end example
Here is an explanation of the code:
@enumerate
@item
The relevent modules are imported using guile's @code{use-modules} syntax.
@item
The @code{lalr-spec} syntax is used to generate a (canonical)
specification from the grammar and options.  The syntax is imported
from the module @code{(nyacc lalr)}.
@item
The @code{prec<} directive indicates that 
the tokens appearing in the sequence of associativity directives
should be interpreted in increasing order of precedence.  The
associativity statements @code{left} indicate that the tokens have left
associativity.  So, in this grammar @code{+}, @code{-}, @code{*}, and
@code{/} are left associative, @code{*} and @code{/} have equal
precedence, @code{+} and @code{-} have equal precedence, but @code{*}
and @code{/} have higher precedence than @code{+} and @code{-}.
(Note: this syntax may change in the future.)
@item
The @code{start} directive indicates which left-hand symbol in the
grammar is the starting symbol for the grammar.
@item
The @code{grammar} directive is used to specify the production rules.
In the example above one left-hand side is associated with multiple
right hand sides.  But this is not required.
@itemize
@item
Multiple right-hand sides can be written for a single left-hand side.  
@item
Non-terminals are indicated as normal identifiers.
@item
Terminals are indicated as non-identifiers using double-quotes
(e.g., @code{"+"}), scheme character syntax (e.g., @code{#\+}), or
quoted identifiers (e.g., @code{'+}).  There is no syntax to declare
tokens.
@item
The reserved symbol @code{'$fx} indicates an unsigned integer.  The
lexical analyzer tools will emit this token when an integer is
detected in the input.
@item
A quoted identifier cannot match a normal identifier.  For
example, one could not use @code{function} to indicate a non-terminal
and @code{"function"} to indicate a terminal.  The reader will signal
an error when this condition is detected.
@item
Within the right-hand side specification a @code{$$} form is used to
specify an action associated with the rule.  Ordinarily, the action
appears as the last element of a right-hand side, but mid-rule
actions are possible (see Section TBD).
@item
The output of @code{lalr-spec} is an associative array so you can
peek at the internals using standard Scheme procedures.
@end itemize
@item
The machine is generated using the procedure @code{make-lalr-machine}.
This routine does the bulk of the processing to produce an LALR(1)
automata.
@item
Generating a parser function requires a few steps.  The first step we
use is to create a lexical analyzer (generator).
@example
(gen-lexer (make-lexer-generator (assq-ref calc-mach 'mtab)))
@end example
We build a generator because a lexical analyzer may require state
(e.g., line number, mode).  The generator is constructed from the
@dfn{match table} provided by the machine.  The procedure
@code{make-lexer-generator} is imported from the module @code{(nyacc
lex)}.  Optional arguments to @code{make-lexer-generator} allow the
user to specify how identifiers, comments, numbers, etc are read in.
@item
The next item in the program is
@example
  (calc-parser (make-lalr-parser calc-mach)))
@end example
This code generates a parser (procedure) from the machine and the
match table.  The match table is the handshake between the lexical
analyzer and the parser for encoding tokens.  In this example the
match table is symbol based, but there is an option to hash these
symbols into integers.  See Section TBD.
@item
The actual parser that we use calls the generated parser with a
lexical analyser created from the generator.
@example
    (lambda () (calc-parser (gen-lexer)))))
@end example
Note that @code{parse-expr} is a thunk: a procedure of no arguments.
@item
Now we run the parser on an input string.  The lexical analyzer reads
code from @code{(current-input-port)} so we set up the environment
using @code{with-input-from-string}.   See the Input/Ouput section of
the Guile Reference Manual for more information.
@example
(define res (with-input-from-string "1 + 4 / 2 * 3 - 5" parse-expr))
@end example
@item
Lastly, we print the result out along with the expected result.
@end enumerate

If we execute the example file above we should get the following:
@example
$ guile calc.scm
expect 2; get 2
$
@end example

@section Example for Production Parser

@subsection Generating the Tables

@subsection Running the Compiler

@example
(use-modules (nyacc parser)
(use-modules (nyacc lex)
(use-modules (nyacc lang util)

@end example

@section The Grammar Specification

Explain it all

@subsection Recovery from Syntax Errors

The grammar specification allows the user to handle some syntax
errors.  This allows parsing to continue.  The behavior is similar
to parser generators like @emph{yacc} or @emph{bison}.  The following
production rule-list allows the user to trap an error.
@example
(line
  ("\n")
  (exp "\n")
  ($error "\n"))
@end example
@noindent
If the current input token does not match the grammar, then the parser
will skip input tokens until a @code{"\n"} is read.  The default
behavior is to generate an error message: @emph{"syntax error"}.
To provide a user-defined handler just add an action for the rule:
@example
(line
  ("\n")
  (exp "\n")
  ($error "\n" ($$ (format #t "line error\n"))))
@end example
@noindent
Note that if the action is not at the end of the rule then the default
recovery action (@emph{"syntax error"}) will be executed.

@section The Match Table
In some parser generators one declares terminals in the grammar file
and the generator will provide an include file providing the list of
terminals along with the associated ``hash codes''.  In @sc{nyacc} the
terminals are detected in the grammar as non-identifiers: strings
(e.g., @code{"for"}), symbols (e.g., @code{'$ident}) or characters
(e.g., @code{#\+}).   The machine generation phase of the parser 
generates a match table which is an a-list of these objects along with
the token code.  These codes are what the lexical analyzer should return.
BLA Bla bla.  So in the end we have
@itemize
@item
The user specifies the grammar with terminals in natural form
(e.g., @code{"for"}).
@item
The parser generator internalizes these to symbols or integers, and generates
an a-list, the match table,  of (natural form, internal form).
@item
The programmer provides the match table to the procedure that builds 
a lexical analyzer generator (e.g., @code{make-lexer-generator}).
@item
The lexical analyzer uses this table to associate strings in the input
with entries in the match table.   In the case of keywords the keys will
appear as strings (e.g., @code{for}), whereas in the case of special items,
processed in the lexical analyzer by readers (e.g., @code{read-num}), the
keys will be symbols (e.g., @code{'$fl}).
@item
The lexical analyzer returns pairs in the form (internal form, natural form)
to the parser.  Note the reflexive behavior of the lexical analyzer.  It
was built with pairs of the form (natural form, internal form) and returns
pairs of the form (internal form, natural form).
@end itemize

Now one item need to be dealt with and that is the token value for the 
default.  It should be @code{-1} or @code{'$default}. WORK ON THIS.

@node Parsing
@chapter Modules for Constructing Parsers and Lexical Analyzers

@emph{nyacc} provides several modules:
@table @asis
@item lalr
This is a module providing macros for generating specifications, 
machines and parsers.
@item lex
This is a module providing procedures for generating lexical analyzers.
@item util
This is a module providing utilities used by the other modules.
@end table

@section The @code{lalr} Module
WARNING: This section is quite crufty.

The @code{lalr1} module provides syntax and procedures for building LALR
parsers.  The following syntax and procedures are exported:
@itemize
@item
@code{lalr-spec} syntax
@item
@code{make-lalr-machine} procedure
@end itemize

We have (experimental) convenience macros:
@example
($? foo bar baz) => ``foo bar baz'' occurs never or once
($* foo bar baz) => ``foo bar baz'' occurs zero or more times
($+ foo bar baz) => ``foo bar baz'' occurs one or more times
@end example
@noindent
However, these have hardcoded actions and are considered to be,
in current form, unattractive for practical use.

Todo: discuss
@itemize
@item
reserved symbols (e.g., @code{$fixed}, @code{$ident}, @code{$empty})
@item
Strings of length one are equivalent to the corresponding character.
@item
@code{(pp-lalr-grammar calc-spec)}
@item
@code{(pp-lalr-machine calc-mach)}
@item
@code{(define calc-mach (compact-mach calc-mach))}
@item
@code{(define calc-mach (hashify-machine calc-mach))}
@item
The specification for @code{expr} could have been expressed using
@example
  (expr (expr "+" expr ($$ (+ $1 $3))))
  (expr (expr "-" expr ($$ (- $1 $3))))
  (expr (expr "*" expr ($$ (* $1 $3))))
  (expr (expr #\/ expr ($$ (/ $1 $3))))
  (expr ('$fx ($$ (string->number $1))))
@end example
@item
rule-base precedence
@item
multiple precedence statements so that some items can be unordered
@example
(prec< "then" "else")
(prec< "t1" "t2" "t3" "t4" "t5")
=> ((t1 . t2) (t2 . t3) (t3 . t4) (t4 . t5) (then . else))
@end example
@end itemize

@c (expect 1)
@c (notice "Copyright (C) 2099 John Doe")

@section The @code{lex} Module

The @sc{nyacc} @code{lex} module provide routines for constructing
lexical analyzers.  The intension is to provide routines to make
construction easy, not necessarily the most efficient.

@section The @code{export} Module
@sc{Nyacc} provides routines for exporting @sc{nyacc} grammar
specifications to other LALR parser generators.

The Bison exporter uses the following rules:
@itemize
@item
Terminals expressed as strings which look like C identifiers are
converted to symbols of all capitals.  For example @code{"for"} is
converted to @code{FOR}.
@item
Strings which are not like C identifiers and are of length 1 are
converted to characters.  For example, @code{"+"} is converted to @code{'+'}.
@item
Characters are converted to C characters.
For example, @code{#\!} is converted to @code{'!'}.
@item
Multi-character strings that do not look like identifiers are
converted to symbols of the form @code{ChSeq_@i{i}_@i{j}_@i{k}} where
@i{i}, @i{j} and @i{k} are decimal representations of the character
code.  For example @code{"+="} is converted to @code{ChSeq_43_61}.
@item
Terminals expressed as symbols are converted as-is but @code{$} and @code{-}
are replaced with @code{_}.
@end itemize

TODO: Export to Bison xml format.

The Guile exporter uses the following rules: TBD.

@node Translation
@chapter Language Translation

Under @samp{examples/nyacc} are utilities for translating languages
along with some samples.  The approach that is used here is to parse
languages into a SXML based parse tree and use the SXML modules in
Guile to translate.  We have built a javascript to tree-il translater
which means that one can execute javascript at the Guile command line:
@example
scheme@@(guile-user)> ,L javascript
need to complete
@end example

@section Tagged-Lists
In actions in nyacc can use our tagged-lists to build the trees.
For example, building a statement list for a program might go like this:
@example
  (program
   (stmt-list ($$ `(program ,(tl->list $1))))
   (...))
  (stmt-list
   (stmt ($$ (make-tl 'stmt-list $1)))
   (stmt-list stmt ($$ (tl-append $1 $2))))
@end example

@section Working with SXML Based Parse Trees
To work with the trees described in the last section use
@example
(sx-ref tree 1)
(sx-attr tree)
(sx-attr-ref tree 'item)
(sx-tail tree 2)
@end example

@section Example: Converting Javascript to Tree-IL

This illustrates translation with @code{foldts*-values} and
@code{sxml-match}. 


@node Administrative
@chapter Administrative Notes

@section Installation
Installation instructions are included in the top-level file
@file{README.nyacc} of the source distribution.

@section Reporting Bugs
Bug reporting will be dealt with once the package is place on a 
publically accessible source repository.

@section The Free Documentation License
The Free Documentation License is included in the Guile Reference
Manual.  It is included with the @sc{nyacc} source as the file 
COPYING.DOC.

@node Todos
@chapter Todos, Notes, Ideas
Todo/Notes/Ideas:
@table @asis
@item 16
add error handling (lalr-spec will now return #f for fatal error)
@item 3
support other target languages:
(write-lalr-parser pgen "foo.py" #:lang 'python)
@item 6
export functions to allow user to control the flow
i.e., something like: (parse-1 state) => state
@item 9
macros - gotta be scheme macros but how to deal with other stuff
(macro ($? val ...) () (val ...))
(macro ($* val ...) () (_ val ...))
(macro ($+ val ...) (val ...) (_ val ...))
idea: use $0 for LHS
@item 10
support semantic forms: (1) attribute grammars, (2) translational
semantics, (3) operational semantics, (4) denotational semantics
@item 13
add ($abort) and ($accept)
@item 18
keep resolved shift/reduce conflicts for pp-lalr-machine
(now have rat-v -- removed action table -- in mach, need to add to pp)
@item 19
add a location stack to the parser/lexer
@item 22
write parser file generator (working prototype)
@item 25
think
@item 26
Fix lexical analyzer to return tval, sval pairs using @code{cons-source} 
instead of @code{cons}.  This will then allow support of location info.
@end table


@node References
@chapter References

@table @asis
@item [DB]
Aho, A.V., Sethi, R., and Ullman, J. D., ``Compilers: Principles,
Techniques and Tools,'' Addison-Wesley, 1985 (aka the Dragon Book)
@item [DP]
DeRemer, F., and Pennello, T., ``Efficient Computation of LALR(1)
Look-Ahead Sets.'' ACM Trans. Prog. Lang. and Systems, Vol. 4, No. 4.,
Oct. 1982, pp. 615-649.
@item [RPC]
R. P. Corbett, ``Static Semantics and Compiler Error Recovery,''
Ph.D. Thesis, UC Berkeley, 1985.
@end table


@c Old Stuff, to be removed
@ifset skip
In the DB an item is used to refer to the position in a production and
the position with associated lookaheads that give the possible set of
terminals that can generate a reduction when the item is a candidate for
reduction (i.e., the dot appears at the end of the p-rule). In this
report we use the terms @emph{item} for the position and @emph{la-item}
for the position and associated lookaheads.  An example of an la-item
is as follows:
@example
A => B . C D, e/f/g
@end example
@noindent
where @code{e/f/g} is a tuple of terminals which can appear at
@example
A => B C D ., e/f/g
@end example
@noindent
We denote an item in the code using a cons with the index of the p-rule
in the car and the index of the right-hand side symbol after the dot
in the cdr.  The end of p-rule will be denoted with index @code{-1}.
So if the rule @samp{A=>BCD} appears as index 7, then the above would
be item @code{(7 . 1)} or la-item @code{((7 . 1) e f g)}.
@end ifset

@bye
@c --- last line
